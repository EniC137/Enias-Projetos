{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profitable App Profiles for the App Store and Google Play Markets\n",
    "\n",
    "The goal of this project is to analyze the data of the App Store and Google Play markets to find the profile of Mobile App's that are more profitable. \n",
    "\n",
    "The setting:\n",
    "We are working as Data Analyst at a Company that builds free to use Mobile Apps for Android and IOS smartphones. \n",
    "\n",
    "The main source of revenue from free to use apps are the ads revenue. This means that our revenue is influenced by the number of users.\n",
    "\n",
    "Our goal is to help the developers to decide the type of app to build that brings the most ad revenue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and Exploring the Data\n",
    "\n",
    "The complete data sets of the App Store and Google Play Markets are too big and costly to analyze, so we will use a sample data set instead. \n",
    "\n",
    "The Sample data consist of two data sets, one with approximately 10,000 Android apps from Google Play store, Collected in August of 2018, and another with 7,000 IOS Apps from the APP store, Collected in July 2017.\n",
    "\n",
    "We will start by opening and exploring these two data sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x90 in position 2755: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-243fad7591b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfile_and\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'googleplaystore.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mreader_and\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_and\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mandroid_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader_and\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mandroid_header\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mandroid_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mandroid_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mandroid_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x90 in position 2755: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "# The Google Play Data Set #\n",
    "from csv import reader\n",
    "file_and = open('googleplaystore.csv', 'r')\n",
    "reader_and = reader(file_and)\n",
    "android_data = list(reader_and)\n",
    "android_header = android_data[0]\n",
    "android_data = android_data[1:]\n",
    "\n",
    "# The Apple App Store Data Set #\n",
    "file_ios = open('AppleStore.csv','r')\n",
    "reader_ios = reader(file_ios)\n",
    "ios_data = list(reader_ios)\n",
    "ios_header = ios_data[0]\n",
    "ios_data = ios_data[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easy for us to explore the two data sets, we will creat a function that shows us the data sets in a more readable way. \n",
    "\n",
    "This function will be called `explore_data()` and will have an option to show the number of rows and columns for any data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the explore data function #\n",
    "\n",
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new empty line after each row\n",
    "        \n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(android_header)\n",
    "print('\\n')\n",
    "explore_data(android_data, 0,3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Dataset has 13 Columns, wich 7 can be useful for our analysis. \n",
    "These are: \"`App, category, Reviews, Installs, Type, Price, and Genres`\". \n",
    "\n",
    "For more information about the dataset and its columns, [Google Play Documentation](https://www.kaggle.com/lava18/google-play-store-apps).\n",
    "\n",
    "Up next, the App Store Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ios_header)\n",
    "print('\\n')\n",
    "explore_data(ios_data, 0,3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has 16 columns and different column names. From this dataset, we can use the following 6 columns: \"`\n",
    "track_name, currency, price, rating_count_tot, rating_count_ver and prime_genre`\".\n",
    "\n",
    "For more information about the columns of this dataset, [App Store Documentation](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps/home). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data\n",
    "\n",
    "We need to clean the data before we analyze it. We are looking to find a profile that matches the type of app we want to build, free and for English-Speeking users. So we need to remove apps that aren't free and/or non-English.\n",
    "\n",
    "Also, The Google Play data set has a dedicated [discussion section](https://www.kaggle.com/lava18/google-play-store-apps/discussion), and we can see that [one of the discussions](https://www.kaggle.com/lava18/google-play-store-apps/discussion/66015) describes an error for row 10472.\n",
    "\n",
    "Let's compare it to the header and another row that is correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(android_header) #Header\n",
    "print('\\n')\n",
    "print(android_data[1]) #Row with correct Data\n",
    "print('\\n')\n",
    "print(android_data[10472]) #Row with incorrect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The app on row 10472 has a rating of 19. This is incorrect beacause the maximum rating on the Google Play store is 5. \n",
    "\n",
    "So we remove this row from our dataset by using the `del` statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(android_data))\n",
    "del android_data[10472] #don't run this more thant once, it will delete the new 10472 row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(android_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates\n",
    "\n",
    "#### Part one: Identifying Duplicates\n",
    "\n",
    "With large datasets, it's pretty to have duplicated entries. A good example is *Instagram* in the Google Play Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insta = 0\n",
    "for i in android_data:\n",
    "    name = i[0]\n",
    "    if name == 'Instagram':\n",
    "        print(i)\n",
    "        insta += 1\n",
    "print('\\n')\n",
    "print('Instagram has ', insta, ' entries')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look for all the apps that have the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_apps = []\n",
    "duplicate_apps = []\n",
    "\n",
    "for app in android_data:\n",
    "    name = app[0]\n",
    "    if name in unique_apps:\n",
    "        duplicate_apps.append(name)\n",
    "    else:\n",
    "        unique_apps.append(name)\n",
    "        \n",
    "print('Number of unique apps:',len(unique_apps) )\n",
    "print('\\n')\n",
    "print('Number of duplicates:', len(duplicate_apps))\n",
    "print('\\n')\n",
    "print('Examples of duplicates:', duplicate_apps[:5])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to remove the duplicates and keep only one entry. We must keep the best entry, so we have the best data for our analysis. \n",
    "\n",
    "We can assume that the reason there are multiple entries is that the datasets have entries for different periods of the same app. The best data is the most recent, and though we have the app version, we may have multiple entries of the same version. The best alternative is to look at the reviews numbers, the more reviews, the more recent the data should be. The reviews are on column number 4.  \n",
    "\n",
    "To clean the data, we will:\n",
    "- Creat a dictionary with unique apps that have the highest number of reviews, named `reviews_max`\n",
    "- Use the `reviews_max` to verify wich entries have the highest number of reviews on our data set, and put it in a list to be the only entry for each app. We will also use the `already_added` to keep track apps that have multiple entries and the same number of reviews. \n",
    "This list will be called `android_clean` and has to be as long as the `unique_apps` list.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_max = {}\n",
    "\n",
    "for app in android_data:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[3])\n",
    "    \n",
    "    if name in reviews_max and (reviews_max[name] < n_reviews):\n",
    "        reviews_max[name] = n_reviews\n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name] = n_reviews\n",
    "        \n",
    "print('Expected length:', len(android_data) - len(duplicate_apps) )\n",
    "print('\\n')\n",
    "print('Dictionary length:', len(reviews_max))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_clean = []\n",
    "already_added = []\n",
    "\n",
    "for app in android_data:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[3])\n",
    "    \n",
    "    if n_reviews == reviews_max[name] and name not in already_added:\n",
    "        android_clean.append(app)\n",
    "        already_added.append(name)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we confirm if our dataset has the same number of entries as the `unique_apps` list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Expected Lenght for Clean Android Data:', len(unique_apps))\n",
    "print('\\n')\n",
    "explore_data(android_clean, 0,3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Non-English Apps\n",
    "\n",
    "### Part One: Identifying Duplicates\n",
    "\n",
    "Another criteria for our Analysis is that our is is going to be designed for English speaking users. Only this time, it happens to both of our datasets.\n",
    "So we will take the action and identify those apps and clean them from our datasets. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ios_data[813][1])\n",
    "print(ios_data[6731][1])\n",
    "print('\\n')\n",
    "print(android_clean[4412][0])\n",
    "print(android_clean[7940][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way we indentify these apps is by checking if the app name contains any letter or symbol thats is mot commonly used in English-text. The English alphabet, numbers and punctuation marks and other symbols (+, -, * etc.) are used in English-text. \n",
    "\n",
    "These characters are encoded using the ASCII standard. Each ASCII character has a number between 0 and 127 associated with it. We can find this number in python by uing the `ord()` function and we will use it to build our `eng_ver()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eng_ver(string):\n",
    "    \n",
    "    for i in string:\n",
    "        if ord(i) > 127:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test of our eng_ver Function\n",
    "print(eng_ver('Instagram'))\n",
    "print(eng_ver('爱奇艺PPS -《欢乐颂2》电视剧热播'))\n",
    "print(eng_ver('Docs To Go™ Free Office Suite'))\n",
    "print(eng_ver('Instachat 😜'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Function works fine, except for when the App name has a emoji or other symbols inside of it. (Example: ™ and 😜). \n",
    "\n",
    "In this form, our function will delete usefull apps for our analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part two: Advanced Filter\n",
    "\n",
    "To minimize the impact of data loss, we'll only remove an app if its name has more than three non-ASCII characters:\n",
    "\n",
    "**(Text from Solution notebook)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eng_ver(string):\n",
    "    ver_counter = 0\n",
    "    \n",
    "    for i in string:     \n",
    "        if ord(i) > 127:\n",
    "            ver_counter +=1\n",
    "            \n",
    "    if ver_counter > 3:\n",
    "        return False\n",
    "            \n",
    "    return True\n",
    "\n",
    "print(eng_ver('Docs To Go™ Free Office Suite'))\n",
    "print(eng_ver('Instachat 😜'))\n",
    "print(eng_ver('爱奇艺PPS -《欢乐颂2》电视剧热播'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is still not perfect, and very few non-English apps might get past our filter, but this seems good enough at this point in our analysis — we shouldn't spend too much time on optimization at this point.\n",
    "\n",
    "**(Text from Solution notebook)**\n",
    "\n",
    "Below, we use the is_english() function to filter out the non-English apps for both data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_clean_eng = []\n",
    "ios_clean_eng = []\n",
    "\n",
    "for i in android_clean:\n",
    "    name = i[0]\n",
    "    if eng_ver(name):\n",
    "        android_clean_eng.append(i)\n",
    "\n",
    "for i in ios_data:\n",
    "    name = i[1]\n",
    "    if eng_ver(name):\n",
    "        ios_clean_eng.append(i)\n",
    "        \n",
    "explore_data(android_clean_eng, 0,3,True)\n",
    "print('\\n')\n",
    "explore_data(ios_clean_eng, 0, 3, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolating the Free Apps\n",
    "\n",
    "As we mentioned in the introduction, we only build apps that are free to download and install, and our main source of revenue consists of in-app ads. Our data sets contain both free and non-free apps, and we'll need to isolate only the free apps for our analysis. Below, we isolate the free apps for both our data sets.\n",
    "\n",
    "**(Text from Solution notebook)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_final = []\n",
    "ios_final = []\n",
    "\n",
    "for app in android_clean_eng:\n",
    "    price = app[7]\n",
    "    if price == '0' :\n",
    "        android_final.append(app)\n",
    "        \n",
    "for app in ios_clean_eng:\n",
    "    price = app[4]\n",
    "    if price == '0.0':\n",
    "        ios_final.append(app)\n",
    "        \n",
    "print('Android Apps left in Dataset:',len(android_final))\n",
    "print('\\n')\n",
    "print('IOS Apps:', len(ios_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're left with 8864 Android apps and 3222 iOS apps, which should be enough for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Most Common Apps by Genre\n",
    "### Part One\n",
    "As we mentioned in the introduction, our aim is to determine the kinds of apps that are likely to attract more users because our revenue is highly influenced by the number of people using our apps.\n",
    "\n",
    "To minimize risks and overhead, our validation strategy for an app idea is comprised of three steps:\n",
    "\n",
    "1. Build a minimal Android version of the app, and add it to Google Play.\n",
    "2. If the app has a good response from users, we then develop it further.\n",
    "3. If the app is profitable after six months, we also build an iOS version of the app and add it to the App Store.\n",
    "\n",
    "Because our end goal is to add the app on both the App Store and Google Play, we need to find app profiles that are successful on both markets. For instance, a profile that might work well for both markets might be a productivity app that makes use of gamification.\n",
    "\n",
    "Let's begin the analysis by getting a sense of the most common genres for each market. For this, we'll build a frequency table for the prime_genre column of the App Store data set, and the Genres and Category columns of the Google Play data set.\n",
    "\n",
    "### Part Two\n",
    "We'll build two functions we can use to analyze the frequency tables:\n",
    "\n",
    "- One function to generate frequency tables that show percentages\n",
    "- Another function that we can use to display the percentages in a descending order\n",
    "\n",
    "**(Text From Solution Notebook)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def freq_table(dataset, index):\n",
    "    freq_table_dic = {}\n",
    "    total_freq_number = 0\n",
    "    \n",
    "    for i in dataset:\n",
    "        total_freq_number +=1\n",
    "        freq_col = i[index]  \n",
    "        if freq_col in freq_table_dic:\n",
    "            freq_table_dic[freq_col] += 1\n",
    "        \n",
    "        else:\n",
    "            freq_table_dic[freq_col] = 1\n",
    "        \n",
    "   \n",
    "    freq_table_perc = {}\n",
    "    for i in freq_table_dic:\n",
    "        percentage = (freq_table_dic[i]/total_freq_number) * 100\n",
    "        freq_table_perc[i] = percentage\n",
    "\n",
    "    return freq_table_perc\n",
    "        \n",
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "\n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])\n",
    "        \n",
    "display_table(ios_final, -5)\n",
    "print('\\n')\n",
    "display_table(android_final, -4)\n",
    "print('\\n')\n",
    "display_table(android_final, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Part Three\n",
    "\n",
    "#### App Store: Prime Genre\n",
    "We can see that among the free English apps, more than a half (58.16%) are games. Entertainment apps are close to 8%, followed by photo and video apps, which are close to 5%. Only 3.66% of the apps are designed for education, followed by social networking apps which amount for 3.29% of the apps in our data set.\n",
    "\n",
    "The general impression is that App Store (at least the part containing free English apps) is dominated by apps that are designed for fun (games, entertainment, photo and video, social networking, sports, music, etc.), while apps with practical purposes (education, shopping, utilities, productivity, lifestyle, etc.) are more rare. However, the fact that fun apps are the most numerous doesn't also imply that they also have the greatest number of users — the demand might not be the same as the offer.\n",
    "\n",
    "\n",
    "####  Google Play: Category\n",
    "Let's continue by examining the Genres and Category columns of the Google Play data set (two columns which seem to be related).\n",
    "\n",
    "The landscape seems significantly different on Google Play: there are not that many apps designed for fun, and it seems that a good number of apps are designed for practical purposes (family, tools, business, lifestyle, productivity, etc.). However, if we investigate this further, we can see that the family category (which accounts for almost 19% of the apps) means mostly games for kids.\n",
    "\n",
    "[![img](https://s3.amazonaws.com/dq-content/350/py1m8_family.png)](https://play.google.com/store/apps/category/FAMILY?hl=en)\n",
    "\n",
    "#### Google Play: Genres\n",
    "Even so, practical apps seem to have a better representation on Google Play compared to App Store. This picture is also confirmed by the frequency table we see for the Genres column.\n",
    "\n",
    "The difference between the Genres and the Category columns is not crystal clear, but one thing we can notice is that the Genres column is much more granular (it has more categories). We're only looking for the bigger picture at the moment, so we'll only work with the Category column moving forward.\n",
    "\n",
    "Up to this point, we found that the App Store is dominated by apps designed for fun, while Google Play shows a more balanced landscape of both practical and for-fun apps. Now we'd like to get an idea about the kind of apps that have most users.\n",
    "\n",
    "**(Text From Solution notebook)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prime_genre_freq = freq_table(ios_final, -5)\n",
    "\n",
    "for genre in prime_genre_freq:\n",
    "    total = 0\n",
    "    len_genre = 0\n",
    "    \n",
    "    for app in ios_final:\n",
    "        genre_app = app[-5]\n",
    "        if genre == genre_app:\n",
    "            users_app = float(app[5])\n",
    "            total += users_app\n",
    "            len_genre += 1\n",
    "\n",
    "    avg_user_rat_prime = total / len_genre\n",
    "\n",
    "    print(genre, \":\", avg_user_rat_prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, navigation apps have the highest number of user reviews, but this figure is heavily influenced by Waze and Google Maps, which have close to half a million user reviews together.\n",
    "\n",
    "The same pattern applies to social networking apps, where the average number is heavily influenced by a few giants like Facebook, Pinterest, Skype, etc. Same applies to music apps, where a few big players like Pandora, Spotify, and Shazam heavily influence the average number.\n",
    "\n",
    "Our aim is to find popular genres, but navigation, social networking or music apps might seem more popular than they really are. The average number of ratings seem to be skewed by very few apps which have hundreds of thousands of user ratings, while the other apps may struggle to get past the 10,000 threshold. We could get a better picture by removing these extremely popular apps for each genre and then rework the averages, but we'll leave this level of detail for later.\n",
    "\n",
    "Reference apps have 74,942 user ratings on average, but it's actually the Bible and Dictionary.com which skew up the average rating.\n",
    "\n",
    "However, this niche seems to show some potential. One thing we could do is take another popular book and turn it into an app where we could add different features besides the raw version of the book. This might include daily quotes from the book, an audio version of the book, quizzes about the book, etc. On top of that, we could also embed a dictionary within the app, so users don't need to exit our app to look up words in an external app.\n",
    "\n",
    "This idea seems to fit well with the fact that the App Store is dominated by for-fun apps. This suggests the market might be a bit saturated with for-fun apps, which means a practical app might have more of a chance to stand out among the huge number of apps on the App Store.\n",
    "\n",
    "Other genres that seem popular include weather, book, food and drink, or finance. The book genre seem to overlap a bit with the app idea we described above, but the other genres don't seem too interesting to us:\n",
    "\n",
    "- Weather apps — people generally don't spend too much time in-app, and the chances of making profit from in-app adds are low. Also, getting reliable live weather data may require us to connect our apps to non-free APIs.\n",
    "\n",
    "- Food and drink — examples here include Starbucks, Dunkin' Donuts, - McDonald's, etc. So making a popular food and drink app requires actual cooking and a delivery service, which is outside the scope of our company.\n",
    "\n",
    "- Finance apps — these apps involve banking, paying bills, money transfer, etc. Building a finance app requires domain knowledge, and we don't want to hire a finance expert just to build an app.\n",
    "\n",
    "**(Text from Solutions Notebook)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_freq = freq_table(android_final, 1)\n",
    "\n",
    "for category in cat_freq:\n",
    "    total = 0\n",
    "    len_category = 0\n",
    "    \n",
    "    for app in android_final:\n",
    "        category_app = app[1]\n",
    "        \n",
    "        if category_app == category:\n",
    "            n_installs = app[5]\n",
    "            n_installs = n_installs.replace('+','')\n",
    "            n_installs = n_installs.replace(',','')\n",
    "            n_installs = float(n_installs)\n",
    "            total += n_installs\n",
    "            len_category += 1\n",
    "            \n",
    "    avg_installs = (total / len_category) * 100\n",
    "    print(category, \":\" , avg_installs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This niche seems to be dominated by software for processing and reading ebooks, as well as various collections of libraries and dictionaries, so it's probably not a good idea to build similar apps since there'll be some significant competition.\n",
    "\n",
    "We also notice there are quite a few apps built around the book Quran, which suggests that building an app around a popular book can be profitable. It seems that taking a popular book (perhaps a more recent book) and turning it into an app could be profitable for both the Google Play and the App Store markets.\n",
    "\n",
    "However, it looks like the market is already full of libraries, so we need to add some special features besides the raw version of the book. This might include daily quotes from the book, an audio version of the book, quizzes on the book, a forum where people can discuss the book, etc.\n",
    "\n",
    "## Conclusions\n",
    "In this project, we analyzed data about the App Store and Google Play mobile apps with the goal of recommending an app profile that can be profitable for both markets.\n",
    "\n",
    "We concluded that taking a popular book (perhaps a more recent book) and turning it into an app could be profitable for both the Google Play and the App Store markets. The markets are already full of libraries, so we need to add some special features besides the raw version of the book. This might include daily quotes from the book, an audio version of the book, quizzes on the book, a forum where people can discuss the book, etc.\n",
    "\n",
    "**(Text from Solutions Notebook)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
